# desafio_redes_neurais_com_tranferlearning
AplicaÃ§Ã£o do mÃ©todo de Transfer Learning em uma rede de Deep Learning na linguagem Python no ambiente COLAB. 

# Estudo de Aprendizado por TransferÃªncia com VGG16 e Keras

Este repositÃ³rio contÃ©m um estudo prÃ¡tico sobre **Aprendizado por TransferÃªncia** (*Transfer Learning*) e **Ajuste Fino** (*Fine-tuning*) utilizando a biblioteca Keras com backend TensorFlow. O projeto foi desenvolvido em um ambiente Google Colab e baseia-se em um tutorial clÃ¡ssico de classificaÃ§Ã£o de imagens.

A principal alteraÃ§Ã£o realizada neste projeto foi a substituiÃ§Ã£o do dataset original `101_ObjectCategories` por um conjunto de imagens customizado da sÃ©rie **Kamen Rider**, com as categorias **Kabuto** e **Zeztz**. Todo o restante da estrutura do projeto foi mantido como no original, com a intenÃ§Ã£o plenamente acadÃªmica de explorar e compreender a tÃ©cnica de Transfer Learning.

## ğŸ§  Conceitos Principais

### Aprendizado por TransferÃªncia / Ajuste Fino

De modo geral, o aprendizado por transferÃªncia refere-se ao processo de aproveitar o conhecimento aprendido em um modelo para o treinamento de outro. O processo envolve pegar uma rede neural existente, previamente treinada em um conjunto de dados maior (como o ImageNet), e usÃ¡-la como base para um novo modelo. Esse mÃ©todo Ã© extremamente popular e eficaz para melhorar o desempenho de uma rede treinada em um conjunto de dados pequeno. A intuiÃ§Ã£o Ã© que as camadas iniciais de uma rede convolucional aprendem caracterÃ­sticas genÃ©ricas (como bordas, texturas e cores) que sÃ£o Ãºteis para diversas tarefas de visÃ£o computacional.

### ExtraÃ§Ã£o de CaracterÃ­sticas vs. Ajuste Fino

Existem duas estratÃ©gias principais no aprendizado por transferÃªncia:

1.  **ExtraÃ§Ã£o de CaracterÃ­sticas:** A rede prÃ©-treinada Ã© usada como um extrator de caracterÃ­sticas fixo. Os pesos de suas camadas sÃ£o "congelados" (nÃ£o sÃ£o atualizados durante o treinamento), e apenas os pesos da nova camada de classificaÃ§Ã£o, adicionada no topo, sÃ£o treinados com o novo dataset.
2.  **Ajuste Fino (Fine-tuning):** AlÃ©m de treinar a nova camada de classificaÃ§Ã£o, permitimos que os pesos de algumas das camadas superiores da rede prÃ©-treinada tambÃ©m sejam atualizados, geralmente com uma taxa de aprendizado baixa. Isso "ajusta" as caracterÃ­sticas mais especializadas da rede para a nova tarefa.

## ğŸš€ Procedimento Adotado

Neste estudo, utilizamos a abordagem de **extraÃ§Ã£o de caracterÃ­sticas**. Carregamos o modelo **VGG16**, treinado no dataset ImageNet, e seguimos os seguintes passos:

1.  **Carregamento dos Dados:** O dataset original `101_ObjectCategories` foi substituÃ­do por um conjunto de imagens com as categorias:
      * `KamenRider/Kabuto`
      * `KamenRider/Zeztz`
2.  **PrÃ©-processamento:** As imagens foram redimensionadas para `224x224` pixels, o formato de entrada esperado pelo VGG16.
3.  **DivisÃ£o do Dataset:** Os dados foram divididos em conjuntos de treino (70%), validaÃ§Ã£o (15%) e teste (15%).

### 1\. Linha de Base: Treinando uma CNN do Zero

Para termos uma base de comparaÃ§Ã£o, primeiro foi criada e treinada uma Rede Neural Convolucional (CNN) simples, do zero. A arquitetura foi a seguinte:

```
Model: "sequential"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)                    â”ƒ Output Shape           â”ƒ       Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ conv2d (Conv2D)                 â”‚ (None, 222, 222, 32)   â”‚           896 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ... (demais camadas)            â”‚ ...                    â”‚           ... â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_1 (Dense)                 â”‚ (None, 3)              â”‚           771 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_5 (Activation)       â”‚ (None, 3)              â”‚             0 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 1,209,315 (4.61 MB)
 Trainable params: 1,209,315 (4.61 MB)
 Non-trainable params: 0 (0.00 B)
```

  - **Resultado:** A precisÃ£o final no conjunto de teste foi de aproximadamente **50%**.

### 2\. Abordagem Principal: Transfer Learning com VGG16

Em seguida, a estratÃ©gia de aprendizado por transferÃªncia foi aplicada:

1.  O modelo **VGG16** foi carregado com seus pesos prÃ©-treinados no ImageNet.
2.  A camada de classificaÃ§Ã£o final (`predictions`), que originalmente classificava 1000 classes, foi removida.
3.  Uma nova camada `Dense` com ativaÃ§Ã£o `softmax` foi adicionada para classificar nossas novas categorias.
4.  Todas as camadas do VGG16 foram **congeladas** (`layer.trainable = False`), de modo que apenas a nova camada de classificaÃ§Ã£o fosse treinada.

<!-- end list -->

```
Model: "functional_20"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)                    â”ƒ Output Shape           â”ƒ       Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layer_1 (InputLayer)      â”‚ (None, 224, 224, 3)    â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ... (camadas do VGG16)          â”‚ ...                    â”‚           ... â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ fc2 (Dense)                     â”‚ (None, 4096)           â”‚    16,781,312 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_2 (Dense)                 â”‚ (None, 3)              â”‚        12,291 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 134,272,835 (512.21 MB)
 Trainable params: 12,291 (48.01 KB)
 Non-trainable params: 134,260,544 (512.16 MB)
```

  - **Resultado:** A precisÃ£o final no conjunto de teste foi de **50%**, embora a acurÃ¡cia de validaÃ§Ã£o durante o treino tenha alcanÃ§ado picos significativamente mais altos, demonstrando a capacidade do modelo de aprender caracterÃ­sticas relevantes muito mais rapidamente.

## ğŸ“Š Resultados e ComparaÃ§Ã£o

O grÃ¡fico abaixo compara a acurÃ¡cia de validaÃ§Ã£o ao longo das Ã©pocas para os dois modelos (azul: CNN do zero; laranja: VGG16 com Transfer Learning).

<img width="1291" height="393" alt="image" src="https://github.com/user-attachments/assets/731bab90-5a58-494e-b566-dec6254d1f0c" />


Fica evidente que a abordagem de Transfer Learning (curva verde) atinge uma acurÃ¡cia de validaÃ§Ã£o superior e mais estÃ¡vel em comparaÃ§Ã£o com o modelo treinado do zero, que demonstra sinais de sobreajuste (*overfitting*) e dificuldade em aprender com o pequeno conjunto de dados.

## ğŸ› ï¸ Como Executar

O cÃ³digo foi desenvolvido em um notebook Google Colab. As principais dependÃªncias sÃ£o:

  * `tensorflow` / `keras`
  * `numpy`
  * `matplotlib`
  * `Pillow`

Basta abrir o arquivo `.ipynb` no Google Colab ou em um ambiente Jupyter e executar as cÃ©lulas em sequÃªncia. O dataset `KamenRider` deve estar na mesma estrutura de pastas mencionada no cÃ³digo.
## PossÃ­veis Melhorias

* **Aumento de Dados (Data Augmentation)**: Aplicar transformaÃ§Ãµes aleatÃ³rias (rotaÃ§Ãµes, zooms, flips) nas imagens de treino para aumentar a variabilidade do dataset e reduzir o overfitting.
* **Ajuste Fino de Mais Camadas**: Descongelar algumas das Ãºltimas camadas do VGG16 e treinÃ¡-las com uma taxa de aprendizado muito baixa (`low learning rate`).
* **Otimizadores e HiperparÃ¢metros**: Experimentar diferentes otimizadores (ex: SGD, RMSprop) e ajustar hiperparÃ¢metros como a taxa de aprendizado e o tamanho do lote (`batch size`). 
